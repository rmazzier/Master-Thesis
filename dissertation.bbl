% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{daniele2019kenn}
A.~Daniele and L.~Serafini, ``Knowledge enhanced neural networks,'' in
  \emph{PRICAI 2019: Trends in Artificial Intelligence}.\hskip 1em plus 0.5em
  minus 0.4em\relax Cham: Springer International Publishing, 2019, pp.
  542--554.

\bibitem{mordvintsev2015inceptionism}
\BIBentryALTinterwordspacing
A.~Mordvintsev, C.~Olah, and M.~Tyka, ``Inceptionism: Going deeper into neural
  networks,'' 2015. [Online]. Available:
  \url{https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html}
\BIBentrySTDinterwordspacing

\bibitem{marra2020relational}
G.~Marra, M.~Diligenti, F.~Giannini, M.~Gori, and M.~Maggini, ``Relational
  neural machines,'' \emph{arXiv preprint arXiv:2002.02193}, 2020.

\bibitem{marcus2018appraisal}
G.~Marcus, ``Deep learning: A critical appraisal,'' Jan. 2018.

\bibitem{o2016weapons}
C.~O'Neil, \emph{Weapons of Math Destruction: How Big Data Increases Inequality
  and Threatens Democracy}.\hskip 1em plus 0.5em minus 0.4em\relax Crown, 2016.

\bibitem{jumper2021highly}
J.~Jumper, R.~Evans, A.~Pritzel, T.~Green, M.~Figurnov, O.~Ronneberger,
  K.~Tunyasuvunakool, R.~Bates, A.~{\v{Z}}{\'\i}dek, A.~Potapenko
  \emph{et~al.}, ``Highly accurate protein structure prediction with
  alphafold,'' \emph{Nature}, vol. 596, no. 7873, pp. 583--589, 2021.

\bibitem{gebru2017using}
T.~Gebru, J.~Krause, Y.~Wang, D.~Chen, J.~Deng, E.~L. Aiden, and L.~Fei-Fei,
  ``Using deep learning and google street view to estimate the demographic
  makeup of the us,'' \emph{arXiv preprint arXiv:1702.06683}, 2017.

\bibitem{schrittwieser2020mastering}
J.~Schrittwieser, I.~Antonoglou, T.~Hubert, K.~Simonyan, L.~Sifre, S.~Schmitt,
  A.~Guez, E.~Lockhart, D.~Hassabis, T.~Graepel \emph{et~al.}, ``Mastering
  atari, go, chess and shogi by planning with a learned model,'' \emph{Nature},
  vol. 588, no. 7839, pp. 604--609, 2020.

\bibitem{lecun1989digits}
Y.~LeCun, B.~Boser, J.~S. Denker, D.~Henderson, R.~E. Howard, W.~Hubbard, and
  L.~D. Jackel, ``Backpropagation applied to handwritten zip code
  recognition,'' \emph{Neural Computation}, vol.~1, no.~4, pp. 541--551, 1989.

\bibitem{rosenblatt1958perceptron}
F.~Rosenblatt, ``The perceptron: a probabilistic model for information storage
  and organization in the brain.'' \emph{Psychological review}, vol.~65, no.~6,
  p. 386, 1958.

\bibitem{sabour2017dynamic}
S.~Sabour, N.~Frosst, and G.~E. Hinton, ``Dynamic routing between capsules,''
  \emph{arXiv preprint arXiv:1710.09829}, 2017.

\bibitem{szegedy2013intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus, ``Intriguing properties of neural networks,'' 12 2013.

\bibitem{buckner2020adversarial}
C.~Buckner, ``Adversarial examples and the deeper riddle of induction: The need
  for a theory of artifacts in deep learning,'' \emph{arXiv preprint
  arXiv:2003.11917}, 2020.

\bibitem{nguyen2015fooled}
A.~Nguyen, J.~Yosinski, and J.~Clune, ``Deep neural networks are easily fooled:
  High confidence predictions for unrecognizable images,'' 06 2015, pp.
  427--436.

\bibitem{jia2017adversarial}
R.~Jia and P.~Liang, ``Adversarial examples for evaluating reading
  comprehension systems,'' 01 2017, pp. 2021--2031.

\bibitem{zhang2019generating}
W.~E. Zhang, Q.~Z. Sheng, A.~A.~F. Alhazmi, and C.~Li, ``Generating textual
  adversarial examples for deep learning models: A survey,'' \emph{arXiv
  preprint arXiv:1901.06796}, p. 129, 2019.

\bibitem{bolukbasi2016debiasing}
T.~Bolukbasi, K.-W. Chang, J.~Zou, V.~Saligrama, and A.~Kalai, ``Man is to
  computer programmer as woman is to homemaker? debiasing word embeddings,'' in
  \emph{Proceedings of the 30th International Conference on Neural Information
  Processing Systems}, ser. NIPS'16.\hskip 1em plus 0.5em minus 0.4em\relax Red
  Hook, NY, USA: Curran Associates Inc., 2016, p. 4356–4364.

\bibitem{goodman2017european}
B.~Goodman and S.~Flaxman, ``European union regulations on algorithmic
  decision-making and a “right to explanation”,'' \emph{AI magazine},
  vol.~38, no.~3, pp. 50--57, 2017.

\bibitem{acm2017transparency}
\BIBentryALTinterwordspacing
ACM. (2017) Statement on algorithmic transparency and accountability. [Online].
  Available:
  \url{https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf}
\BIBentrySTDinterwordspacing

\bibitem{gunning2019xai}
\BIBentryALTinterwordspacing
D.~Gunning and D.~Aha, ``Darpa’s explainable artificial intelligence (xai)
  program,'' \emph{AI Magazine}, vol.~40, no.~2, pp. 44--58, Jun. 2019.
  [Online]. Available:
  \url{https://ojs.aaai.org/index.php/aimagazine/article/view/2850}
\BIBentrySTDinterwordspacing

\bibitem{bromberger1992we}
S.~Bromberger, \emph{On what we know we don't know: Explanation, theory,
  linguistics, and how questions shape them}.\hskip 1em plus 0.5em minus
  0.4em\relax University of Chicago Press, 1992.

\bibitem{lipton2017mythos}
Z.~Lipton, ``The mythos of model interpretability,'' \emph{Communications of
  the ACM}, vol.~61, 10 2016.

\bibitem{doshivelez2017rigorous}
\BIBentryALTinterwordspacing
F.~Doshi-Velez and B.~Kim. (2017) Towards a rigorous science of interpretable
  machine learning. [Online]. Available: \url{https://arxiv.org/abs/1702.08608}
\BIBentrySTDinterwordspacing

\bibitem{Kim2015InteractiveAI}
B.~Kim, ``Interactive and interpretable machine learning models for human
  machine collaboration,'' 2015.

\bibitem{ribeiro2016trust}
M.~Ribeiro, S.~Singh, and C.~Guestrin, ``“why should i trust you?”:
  Explaining the predictions of any classifier,'' 02 2016, pp. 97--101.

\bibitem{burkart2021survey}
N.~Burkart and M.~Huber, ``A survey on the explainability of supervised machine
  learning,'' \emph{Journal of Artificial Intelligence Research}, vol.~70, 01
  2021.

\bibitem{chen2019judicial}
B.~Chen, Y.~Li, S.~Zhang, H.~Lian, and T.~He, ``A deep learning method for
  judicial decision support,'' in \emph{2019 IEEE 19th International Conference
  on Software Quality, Reliability and Security Companion (QRS-C)}, 2019, pp.
  145--149.

\bibitem{zhang2018explainable}
Y.~Zhang and X.~Chen, ``Explainable recommendation: A survey and new
  perspectives,'' \emph{arXiv preprint arXiv:1804.11192}, 2018.

\bibitem{gilpin2018explaining}
L.~Gilpin, D.~Bau, B.~Yuan, A.~Bajwa, M.~Specter, and L.~Kagal, ``Explaining
  explanations: An overview of interpretability of machine learning,'' Oct.
  2018, pp. 80--89.

\bibitem{montavon2018methods}
G.~Montavon, W.~Samek, and K.-R. Müller, ``Methods for interpreting and
  understanding deep neural networks,'' \emph{Digital Signal Processing},
  vol.~73, pp. 1--15, 2018.

\bibitem{Herman2017ThePA}
B.~Herman, ``The promise and peril of human evaluation for model
  interpretability,'' \emph{ArXiv}, vol. abs/1711.07414, 2017.

\bibitem{dosilovic2018explainable}
F.~K. Došilović, M.~Brčić, and N.~Hlupić, ``Explainable artificial
  intelligence: A survey,'' in \emph{2018 41st International Convention on
  Information and Communication Technology, Electronics and Microelectronics
  (MIPRO)}, 2018, pp. 0210--0215.

\bibitem{laurens2008tsne}
\BIBentryALTinterwordspacing
L.~van~der Maaten and G.~Hinton, ``Visualizing data using t-sne,''
  \emph{Journal of Machine Learning Research}, vol.~9, no.~86, pp. 2579--2605,
  2008. [Online]. Available:
  \url{http://jmlr.org/papers/v9/vandermaaten08a.html}
\BIBentrySTDinterwordspacing

\bibitem{mahendran2014understanding}
A.~Mahendran and A.~Vedaldi, ``Understanding deep image representations by
  inverting them,'' 11 2014.

\bibitem{simonyan2013deep}
K.~Simonyan, A.~Vedaldi, and A.~Zisserman, ``Deep inside convolutional
  networks: Visualising image classification models and saliency maps,''
  \emph{preprint}, 12 2013.

\bibitem{wang2016dueling}
Z.~Wang, T.~Schaul, M.~Hessel, H.~Hasselt, M.~Lanctot, and N.~Freitas,
  ``Dueling network architectures for deep reinforcement learning,'' in
  \emph{Proceedings of The 33rd International Conference on Machine Learning},
  ser. Proceedings of Machine Learning Research, M.~F. Balcan and K.~Q.
  Weinberger, Eds., vol.~48.\hskip 1em plus 0.5em minus 0.4em\relax New York,
  New York, USA: PMLR, 20--22 Jun 2016, pp. 1995--2003.

\bibitem{ross2017right}
A.~S. Ross, M.~C. Hughes, and F.~Doshi-Velez, ``Right for the right reasons:
  Training differentiable models by constraining their explanations,''
  \emph{arXiv preprint arXiv:1703.03717}, 2017.

\bibitem{attentionisall2017vaswani}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in
  \emph{Advances in neural information processing systems}, 2017, pp.
  5998--6008.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' \emph{arXiv preprint
  arXiv:1810.04805}, 2018.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.},
  ``An image is worth 16x16 words: Transformers for image recognition at
  scale,'' \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{park2018multimodal}
D.~H. Park, L.~A. Hendricks, Z.~Akata, A.~Rohrbach, B.~Schiele, T.~Darrell, and
  M.~Rohrbach, ``Multimodal explanations: Justifying decisions and pointing to
  the evidence,'' in \emph{Proceedings of the IEEE Conference on Computer
  Vision and Pattern Recognition}, 2018, pp. 8779--8788.

\bibitem{das2017human}
A.~Das, H.~Agrawal, L.~Zitnick, D.~Parikh, and D.~Batra, ``Human attention in
  visual question answering: Do humans and deep networks look at the same
  regions?'' \emph{Computer Vision and Image Understanding}, vol. 163, pp.
  90--100, 2017.

\bibitem{caruana1999case}
R.~Caruana, H.~Kangarloo, J.~D. Dionisio, U.~Sinha, and D.~Johnson,
  ``Case-based explanation of non-case-based learning methods.'' in
  \emph{Proceedings of the AMIA Symposium}.\hskip 1em plus 0.5em minus
  0.4em\relax American Medical Informatics Association, 1999, p. 212.

\bibitem{valiant2003threeproblems}
\BIBentryALTinterwordspacing
L.~G. Valiant, ``Three problems in computer science,'' \emph{J. ACM}, vol.~50,
  no.~1, p. 96–99, Jan. 2003. [Online]. Available:
  \url{https://doi.org/10.1145/602382.602410}
\BIBentrySTDinterwordspacing

\bibitem{richardson2006markov}
M.~Richardson and P.~Domingos, ``Markov logic networks,'' \emph{Machine
  learning}, vol.~62, no. 1-2, pp. 107--136, 2006.

\bibitem{pearl2014probabilistic}
J.~Pearl, \emph{Probabilistic reasoning in intelligent systems: networks of
  plausible inference}.\hskip 1em plus 0.5em minus 0.4em\relax Elsevier, 2014.

\bibitem{wang2008hybrid}
J.~Wang and P.~M. Domingos, ``Hybrid markov logic networks.'' in \emph{AAAI},
  vol.~8, 2008, pp. 1106--1111.

\bibitem{Besold2017NeuralSymbolicLA}
T.~R. Besold, A.~Garcez, S.~Bader, H.~Bowman, P.~M. Domingos, P.~Hitzler, K.-U.
  K{\"u}hnberger, L.~Lamb, D.~Lowd, P.~Lima, L.~Penning, G.~Pinkas, H.~Poon,
  and G.~Zaverucha, ``Neural-symbolic learning and reasoning: A survey and
  interpretation,'' \emph{ArXiv}, vol. abs/1711.03902, 2017.

\bibitem{novak1987first}
V.~Nov{\'a}k, ``First-order fuzzy logic,'' \emph{Studia logica}, vol.~46,
  no.~1, pp. 87--109, 1987.

\bibitem{abadi2016tensorflow}
M.~Abadi, P.~Barham, J.~Chen, Z.~Chen, A.~Davis, J.~Dean, M.~Devin,
  S.~Ghemawat, G.~Irving, M.~Isard \emph{et~al.}, ``Tensorflow: A system for
  large-scale machine learning,'' in \emph{12th $\{$USENIX$\}$ symposium on
  operating systems design and implementation ($\{$OSDI$\}$ 16)}, 2016, pp.
  265--283.

\bibitem{serafini2016logic}
L.~Serafini and A.~d. Garcez, ``Logic tensor networks: Deep learning and
  logical reasoning from data and knowledge,'' \emph{arXiv preprint
  arXiv:1606.04422}, 2016.

\bibitem{sen2008collective}
P.~Sen, G.~Namata, M.~Bilgic, L.~Getoor, B.~Galligher, and T.~Eliassi-Rad,
  ``Collective classification in network data,'' \emph{AI magazine}, vol.~29,
  no.~3, pp. 93--93, 2008.

\bibitem{lu2003link}
Q.~Lu and L.~Getoor, ``Link-based text classification,'' in \emph{IJCAI
  Workshop on Text Mining and Link Analysis}, 2003.

\end{thebibliography}
