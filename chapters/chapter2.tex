%!TEX root = ../dissertation.tex

\chapter{Neural Symbolic Integration}
Here we report different approaches for injecting logical knowledge inside neural networks....

% TODO: STUDIARE BENE DA PAPER KENN
 %TODO possibili intro...
 In spite of the amazing results obtained by deep learning in
 many applications, a real intelligent behavior of an agent acting in a
 complex environment is likely to require some kind of higher-level symbolic
 inference. Therefore, there is a clear need for the definition of a general and
 tight integration between low-level tasks, processing sensorial data that
 can be effectively elaborated using deep learning techniques, and the logic
 reasoning that allows humans to take decisions in complex environments. (from Lyrics paper)

% TODO altra survey interessante con info: https://arxiv.org/pdf/2003.08316.pdf
Interesting pieces from besold et al (neural symbolic integration paper): intuitive motivation for NSI:
in neural computing it is assumed that the mind is an emergent porperty of the brain, and that computational cognitive modelling can lead to valid theories of cognition and offer an understanding of certain cognitive processes (sun 2009)

the Connectionism model should ffer an appropriate representational language for artificial intelligence; in particular this kind of model can replicate parallelism and adaptive learning, present in neuralnetworks: this assures the effectivenes and robusteness of the system, to deal with commonsense knowledge.. all this to say that a purely symbolic approach would not be sufficient (as argued by Valiant 2008 ).

On the other hand, logic is firmly established as a fundamental tool in the modelling of thought and behaviour... We have to concile these two areas.

However when building models that combine both learning and reasoning, one has to conciliate the methodologies of distinct areas (basically statistics vs logic), in order to combine respective advantages and circumvent the shortcomings and limitations of each other. This problem has been identified as a key research challenge and fundamental problem in computer science... (Valiant 2003)

The goals of NSI are to provide a coherent, unifying view for logic and connectionsim, to contribute to the modelling and understanding of cognition and, thereby, behavior, and to produce better computational tools for integrated machine learning and reasoning. In a nutshell: encompasses the high level integration of cognitive abilities and the study of how the brain makes a mental model... at the computational level, it addresses the study of the integration of logic, probabilities, and learning, and the development of new models of computation combining robust learning and efficient reasoning.

So as we can see NSI is a really vast area of research. In our case we are interested in the usage of knowledge inside a neural network. Daniele and Serafini (se metto solo Daniele il prof ci rimane male? lol) \cite{daniele2019kenn} (in realtà la sezione previous work sta anche nel paper di LTN!) subdivide NSI sytstems into three main groups, based on their different objectives:
\begin{enumerate}
	\item \textbf{Differentiable Reasoning }: ... (capire bene cosa significa "reasoning")
	\item \textbf{Inductive Logic Programming} : here the goal is to extract logical knowledge from data, or to refine an existing one
	\item \textbf{Knowledge Guided Learning}: here the goal is Learning in classical ML sense, and Knowledge has the role of supervisor, meaning that the machine should learn according to the base knowledge.
\end{enumerate}

We are interested in the third class of models, the one where KENN belongs. The objective is to improve the performance of a neural network model, by providing a Prior Knowledge which is expressed in terms of logical formulas. At present, two main ways of injecting knowledge inside NN have been employed. The first one involves the usage of a regularization term in the loss function. Indeed, logical rules can be interpreted as costraints for the weights in the learning process; in machine learning, the natural way to introduce costraints in learning is to add a penalization term in the loss function, which represents in some way the satisfaction of the logical rules. The second approach, adopted by KENN, is to directly modify the network architecture: in this way, logical rules are not enforced by external penalizations but are already present in the network topology ... (riscrivere bene)

\section{Regularization Approaches}
Logic Tensor Networks, Semantic based regularization....

\subsubsection{Logic Tensor Networks}
%TODO: è  ancora una bozza.. riscrivere bene...
Logic Tensor Networks (LTN) \cite{serafini2016logic} is a notable example of methods capable of integrating logical knowledge inside neural networks by directly modifying the loss function. To do this, the authors define a differentiable first-order logic language called Real Logic, with which they manage to represent common deep learning tasks, such as clustering, multi-label classification, relational learning, query answering, semi-supervised learning, regression and embedding learning. 
%LTN can also perform reasoning, which is the task of verifying if a formula is a logical consequence of another formula. 
In simple terms, the role of Real Logic is to act as a bridge between the purely symbolic world of logic, and the sub-symbolic world of neural systems. We give a brief summary of the core definitions in Real Logic, in order to understand how learning is possible.

Real Logic is defined over a first order language $\mathcal{L}$ with a signature containing a set of constant symbols (or objects) $\mathcal{C}$, a set of variable symbols $\mathcal{X}$, a set of functional symbols $\mathcal{F}$ and a set of relational symbols (or predicates) $\mathcal{P}$. We refer to the set $\mathcal{S} = \mathcal{C} \cup \mathcal{X} \cup \mathcal{F} \cup  \mathcal{P}$ as the set of symbols of $\mathcal{L}$. Each symbol of the language can belong to different domains (i.e. can be of different types): for example the constant $c_1 \in \mathcal{C}$ can represent a specific person, while the constant $c_2 \in \mathcal{C}$ can represent a specific city. The same concept applies to functions and predicates. To represent the domain of each symbol, it is assumed that there exists a non-empty set $\mathcal{D}$, containing all the domains, which are in turn symbols. Then, to properly assign each symbol to its corresponding domain, the functions $\mathbf{D}, \mathbf{D_{in}}$ and $\mathbf{D_{out}}$ are defined:

\begin{equation*}
\mathbf{D}: \mathcal{X} \cup \mathcal{C} \rightarrow\mathcal{D}
\qquad \qquad
\mathbf{D_{in}}: \mathcal{F} \cup \mathcal{P} \rightarrow\mathcal{D^*}
\qquad \qquad 
\mathbf{D_{out}}: \mathcal{F} \rightarrow\mathcal{D},
\end{equation*}

where $\mathcal{D^*}$ is the set of all finite sequences of symbols in $\mathcal{D}$.
%The set of terms of the language $T$ is recursively defined, to be the smallest set such that...
The point where the symbolic language meets the subsymbolic world of neural networks is in the definition of grounding, which is the process in which each symbol is given its numeric representation. Indeed, in Real Logic, each domain is interpreted as sets of tensors in the real field. In the same way, each constant, variable and term of the language is interpreted as a tensor of real values, and function symbols are interpreted as functions between tensors. Predicates, are interpreted as functions that map tensors into the interval$[0,1]$. So, given $s$ any symbol of $\mathcal{L}$, its grounding is denoted as $\mathcal{G}(s)$. 
%By defining how to apply the grounding for each symbol of $\mathcal{L}$, semantic of $\mathcal{L}$. 
The authors then define how to compute the grounding of formulas, by using the semantics of first-order fuzzy logic. 
The way in which learning becomes possible is by defining parametric definition of grounding for symbols: given a symbol $s$, the parametric grounding of $s$ is a grounding which is not known in advance, and can be computed exclusively by knowing a set of parameters. It is denoted as $\mathcal{G}(s|\theta_s)$, where $\theta_s$ is the set of parameter values that uniquely determines the value of the grounding. It's interesting to note that, based on what kind of symbol we are learning the grounding for, one can identify a corresponding task in machine learning:
\begin{itemize}
	\item If $s \in \mathcal{C}$, corresponds to learning an embedding;
	\item If $s \in \mathcal{F}$, it corresponds to learning generative models, or regression tasks;
	\item If $s \in \mathcal{P}$, it corresponds to learning a classification task.
\end{itemize}

\subsubsection{Semantic Based Regularization}
Semantic Based Regularization (SBR) is a general learning framework designed to integrate domain specific background knowledge in the form of first-order logic (FOL) clauses. To enforce the satisfaction of all the clauses, SBR introduces special regularization terms in the loss function, which represent the satisfaction of the knowledge. Specifically, given a background knowledge represented by set of $H$ clauses, the satisfaction of the $h$-th clause can be represented by the quantity denoted by $0 \leq \phi_h(f) \leq 1$, where $f$ is the vector function learned by the model. From here, the regularization term to be added to the loss function is defined as

$$ \sum_{h=1}^H \lambda_h(1 - \phi_h(f)), $$

where $\lambda_h$ is the weight associated to the $h$-th constraint. A higher value will increase the cost of not satisfying the constraint. The conversion of FOL clauses into differentiable functions is made possible by considering fuzzy generalizations of FOL logic, first introduced in \cite{novak1987first}. This is a natural approach for machine learning tasks, but a major disadvantage over KENN is that, since the clause weights are introduced at the level of the loss function, those cannot be learned and are required to be known in advance. This, of course, is unlikely to happen in real scenarios.

\section{Model Based Approaches}

\subsection{Relational Neural Machines}

