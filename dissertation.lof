\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Intuitive representation of explanations coming from transparent models (left) vs. explanations coming from post-hoc interpretability techniques (right). Transparent models are inherently interpretable by their design; they can be inspected and explanations can be deduced from them. Post-hoc interpretability, on the other hand, refers to a wide range of techniques with which explanations are extracted by any already trained model. \relax }}{9}{figure.caption.13}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Process of image manipulation shown in \cite {mordvintsev2015inceptionism}. From an intuitive point of view, starting from existing real images, the network is asked to enhance the features of the image that resemble the desired object (in this case, starting from an image of a tree, start looking for features that resemble buildings). This process is then repeated, creating a positive feedback loop. As a result, the features of the desired objects appear seemingly out of nowhere.\relax }}{11}{figure.caption.14}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces On the left, example preactivations for the clause $\operatorname {A}(x) \vee \neg \operatorname {B}(x)$ are shown. For both the examples, the same delta ($\delta ^f$) is applied to these preactivations. In the first example, the NN has a high confidence, while in the second one it is much lower. We can see how, when applying the activation function, the actual delta ($\delta ^g$) is much smaller in the first case and larger in the second. This is due to the shape of the sigmoid activation function itself. \relax }}{26}{figure.caption.15}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Example with all the steps needed to compute $\delta ^c$ for the clause $A \vee \neg B$ starting from the vector of preactivations $z$; for this example $w_c=2$. We refer to this process as \textit {clause enhancement}.\relax }}{28}{figure.caption.16}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Illustration of the KENN architecture. Images are replications of the illustrations provided in \cite {daniele2019kenn}.\relax }}{30}{figure.caption.17}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Representation of relational data inside KENN. Specifically, objects and relations can be seen as nodes and edges of a directed graph. The preactivations of each grounded predicate are represented in tables $U$ and $B$. In this example, two unary predicates and one binary predicate are present. Note that in matrix $B$ only the object pairs such that there is a relation between them are reported.\relax }}{32}{figure.caption.18}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces This figure shows an example with all the necessary computations to compute the final delta matrices $\delta U$ and $\delta B$ (in the bottom), starting from matrices $U$ and $B$ (top left).\relax }}{35}{figure.caption.19}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Simple example showing how the relational knowledge is injected in the NN for the Citeseer experiments. In this toy example, features are $4$-dimensional vectors and there are $3$ unary predicates; in the actual experiments, feature vectors have $3703$ components and the output classes are $6$.\relax }}{43}{figure.caption.20}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Relative improvements for the inductive learning task. $95\%$ confidence intervals are provided for our results.\relax }}{44}{figure.caption.22}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Histograms showing the distribution of the accuracies for all the different $500$ runs, for the inductive case. On the left, the accuracies of the base NN vs accuracies of KENN. On the right the distribution of the relative improvements.\relax }}{45}{figure.caption.23}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Relative improvements for the transductive learning task. $95\%$ confidence intervals are provided for our results.\relax }}{47}{figure.caption.25}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Histograms showing the distribution of the accuracies for all the different $500$ runs, for the transductive case. On the left, the accuracies of the base NN vs accuracies of KENN. On the right the distribution of the relative improvements.\relax }}{48}{figure.caption.26}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Scatterplots showing the relation between clause weight and clause compliance, for each clause from $85$ different runs, for each different training percentage. We can observe how, as the training dimension increases, KENN learns to adjust the clause weights according on how much that clause is satisfied in the training set. Each dot in the scatterplots corresponds to a clause in a specific run; the colour of the dot denotes the topic related to that clause.\relax }}{50}{figure.caption.28}%
\addvspace {10\p@ }
